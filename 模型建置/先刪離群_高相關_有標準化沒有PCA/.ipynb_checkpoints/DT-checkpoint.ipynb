{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23157ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "import os\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from __future__ import print_function\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold  # 方差過濾\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c2f751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eye_R_B_W</th>\n",
       "      <th>Eye_L_B_W</th>\n",
       "      <th>Eye_R_H6_W</th>\n",
       "      <th>Eye_L_H1_W</th>\n",
       "      <th>Eye_L_H5_W</th>\n",
       "      <th>Eye_dis_B_W</th>\n",
       "      <th>Eyebrow_dis_W</th>\n",
       "      <th>N_LET_W</th>\n",
       "      <th>Eyebrow_R_H4_W</th>\n",
       "      <th>Eyebrow_L_H2_W</th>\n",
       "      <th>...</th>\n",
       "      <th>Lip_h1_L</th>\n",
       "      <th>Lip_h5_L</th>\n",
       "      <th>Lip_dh3_L</th>\n",
       "      <th>Lip_height_L</th>\n",
       "      <th>face_up_L</th>\n",
       "      <th>face_down_L</th>\n",
       "      <th>face_L_width_L</th>\n",
       "      <th>Eye_to_eyebrow_L_L</th>\n",
       "      <th>eye_to_eyebrow_R_L</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.371029</td>\n",
       "      <td>-0.448980</td>\n",
       "      <td>-0.866893</td>\n",
       "      <td>-0.918080</td>\n",
       "      <td>0.098274</td>\n",
       "      <td>-0.715561</td>\n",
       "      <td>0.074501</td>\n",
       "      <td>-1.025311</td>\n",
       "      <td>-0.273121</td>\n",
       "      <td>0.317896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.485461</td>\n",
       "      <td>-0.638260</td>\n",
       "      <td>-1.168916</td>\n",
       "      <td>-1.429228</td>\n",
       "      <td>-0.399381</td>\n",
       "      <td>0.064321</td>\n",
       "      <td>0.643328</td>\n",
       "      <td>1.024564</td>\n",
       "      <td>1.276503</td>\n",
       "      <td>boss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.396644</td>\n",
       "      <td>-1.499499</td>\n",
       "      <td>1.332962</td>\n",
       "      <td>-0.016496</td>\n",
       "      <td>0.676106</td>\n",
       "      <td>0.214980</td>\n",
       "      <td>-0.494539</td>\n",
       "      <td>-0.234723</td>\n",
       "      <td>2.151637</td>\n",
       "      <td>0.741030</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.364071</td>\n",
       "      <td>-1.649756</td>\n",
       "      <td>-0.114365</td>\n",
       "      <td>-1.331401</td>\n",
       "      <td>2.163930</td>\n",
       "      <td>-1.252541</td>\n",
       "      <td>-2.053611</td>\n",
       "      <td>-0.569419</td>\n",
       "      <td>0.243881</td>\n",
       "      <td>boss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.439104</td>\n",
       "      <td>0.484230</td>\n",
       "      <td>0.009343</td>\n",
       "      <td>-1.378348</td>\n",
       "      <td>0.494758</td>\n",
       "      <td>-1.548462</td>\n",
       "      <td>-1.184414</td>\n",
       "      <td>1.019508</td>\n",
       "      <td>-0.621587</td>\n",
       "      <td>0.675260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.409028</td>\n",
       "      <td>0.665220</td>\n",
       "      <td>1.289591</td>\n",
       "      <td>0.023857</td>\n",
       "      <td>0.386898</td>\n",
       "      <td>0.157466</td>\n",
       "      <td>0.393616</td>\n",
       "      <td>-1.518321</td>\n",
       "      <td>-1.391570</td>\n",
       "      <td>boss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.653748</td>\n",
       "      <td>-0.504374</td>\n",
       "      <td>2.759587</td>\n",
       "      <td>-1.825463</td>\n",
       "      <td>2.538630</td>\n",
       "      <td>-1.897134</td>\n",
       "      <td>-2.224317</td>\n",
       "      <td>3.069776</td>\n",
       "      <td>1.711365</td>\n",
       "      <td>3.198713</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.943542</td>\n",
       "      <td>0.597671</td>\n",
       "      <td>0.288644</td>\n",
       "      <td>-0.299054</td>\n",
       "      <td>0.070247</td>\n",
       "      <td>0.287063</td>\n",
       "      <td>-1.495221</td>\n",
       "      <td>-2.074765</td>\n",
       "      <td>-1.844764</td>\n",
       "      <td>boss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.243426</td>\n",
       "      <td>-1.035791</td>\n",
       "      <td>-1.486453</td>\n",
       "      <td>-1.021156</td>\n",
       "      <td>-0.969298</td>\n",
       "      <td>-1.789011</td>\n",
       "      <td>-0.949778</td>\n",
       "      <td>-3.136693</td>\n",
       "      <td>-1.017479</td>\n",
       "      <td>-2.836990</td>\n",
       "      <td>...</td>\n",
       "      <td>2.218981</td>\n",
       "      <td>2.824092</td>\n",
       "      <td>1.380356</td>\n",
       "      <td>0.103716</td>\n",
       "      <td>1.242597</td>\n",
       "      <td>0.827017</td>\n",
       "      <td>1.088651</td>\n",
       "      <td>-0.701203</td>\n",
       "      <td>0.314433</td>\n",
       "      <td>boss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67303</th>\n",
       "      <td>-0.247230</td>\n",
       "      <td>0.845882</td>\n",
       "      <td>-0.901832</td>\n",
       "      <td>0.457907</td>\n",
       "      <td>-0.499155</td>\n",
       "      <td>-0.375864</td>\n",
       "      <td>2.085433</td>\n",
       "      <td>-0.001246</td>\n",
       "      <td>-0.684678</td>\n",
       "      <td>-1.111386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232581</td>\n",
       "      <td>-0.455388</td>\n",
       "      <td>-0.592585</td>\n",
       "      <td>0.458105</td>\n",
       "      <td>-3.057781</td>\n",
       "      <td>1.112890</td>\n",
       "      <td>0.991555</td>\n",
       "      <td>1.693874</td>\n",
       "      <td>2.298094</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67304</th>\n",
       "      <td>0.336898</td>\n",
       "      <td>-1.065937</td>\n",
       "      <td>-1.351670</td>\n",
       "      <td>-0.312087</td>\n",
       "      <td>-0.566462</td>\n",
       "      <td>-1.045694</td>\n",
       "      <td>-0.341706</td>\n",
       "      <td>-1.171122</td>\n",
       "      <td>-1.139710</td>\n",
       "      <td>-0.729043</td>\n",
       "      <td>...</td>\n",
       "      <td>1.031585</td>\n",
       "      <td>1.013650</td>\n",
       "      <td>0.511776</td>\n",
       "      <td>-0.372693</td>\n",
       "      <td>-1.909245</td>\n",
       "      <td>0.844149</td>\n",
       "      <td>0.721058</td>\n",
       "      <td>-0.262786</td>\n",
       "      <td>-0.675667</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67305</th>\n",
       "      <td>-0.126210</td>\n",
       "      <td>0.098713</td>\n",
       "      <td>-1.277926</td>\n",
       "      <td>0.031775</td>\n",
       "      <td>0.029519</td>\n",
       "      <td>-0.054400</td>\n",
       "      <td>0.022684</td>\n",
       "      <td>-0.925395</td>\n",
       "      <td>-1.129517</td>\n",
       "      <td>-0.804039</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.552749</td>\n",
       "      <td>-0.481648</td>\n",
       "      <td>-1.393494</td>\n",
       "      <td>-1.711341</td>\n",
       "      <td>-0.083537</td>\n",
       "      <td>0.629206</td>\n",
       "      <td>1.788860</td>\n",
       "      <td>-1.349675</td>\n",
       "      <td>1.083243</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67306</th>\n",
       "      <td>1.178550</td>\n",
       "      <td>-0.798004</td>\n",
       "      <td>-0.790639</td>\n",
       "      <td>0.514963</td>\n",
       "      <td>-1.033477</td>\n",
       "      <td>0.695431</td>\n",
       "      <td>0.999174</td>\n",
       "      <td>-1.858378</td>\n",
       "      <td>-0.301002</td>\n",
       "      <td>-1.718476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812409</td>\n",
       "      <td>0.204526</td>\n",
       "      <td>-0.017447</td>\n",
       "      <td>2.027846</td>\n",
       "      <td>-0.400509</td>\n",
       "      <td>1.419143</td>\n",
       "      <td>0.225163</td>\n",
       "      <td>-0.506823</td>\n",
       "      <td>-0.119500</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67307</th>\n",
       "      <td>-0.049421</td>\n",
       "      <td>-0.752788</td>\n",
       "      <td>-1.284975</td>\n",
       "      <td>-0.425240</td>\n",
       "      <td>-0.613935</td>\n",
       "      <td>-0.998181</td>\n",
       "      <td>-0.031247</td>\n",
       "      <td>-1.380678</td>\n",
       "      <td>-1.534513</td>\n",
       "      <td>-1.897627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704872</td>\n",
       "      <td>0.638523</td>\n",
       "      <td>0.902799</td>\n",
       "      <td>-0.486805</td>\n",
       "      <td>-1.215145</td>\n",
       "      <td>0.187233</td>\n",
       "      <td>1.548236</td>\n",
       "      <td>1.497667</td>\n",
       "      <td>1.165196</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67308 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Eye_R_B_W  Eye_L_B_W  Eye_R_H6_W  Eye_L_H1_W  Eye_L_H5_W  Eye_dis_B_W  \\\n",
       "0      -0.371029  -0.448980   -0.866893   -0.918080    0.098274    -0.715561   \n",
       "1       1.396644  -1.499499    1.332962   -0.016496    0.676106     0.214980   \n",
       "2      -1.439104   0.484230    0.009343   -1.378348    0.494758    -1.548462   \n",
       "3      -1.653748  -0.504374    2.759587   -1.825463    2.538630    -1.897134   \n",
       "4       0.243426  -1.035791   -1.486453   -1.021156   -0.969298    -1.789011   \n",
       "...          ...        ...         ...         ...         ...          ...   \n",
       "67303  -0.247230   0.845882   -0.901832    0.457907   -0.499155    -0.375864   \n",
       "67304   0.336898  -1.065937   -1.351670   -0.312087   -0.566462    -1.045694   \n",
       "67305  -0.126210   0.098713   -1.277926    0.031775    0.029519    -0.054400   \n",
       "67306   1.178550  -0.798004   -0.790639    0.514963   -1.033477     0.695431   \n",
       "67307  -0.049421  -0.752788   -1.284975   -0.425240   -0.613935    -0.998181   \n",
       "\n",
       "       Eyebrow_dis_W   N_LET_W  Eyebrow_R_H4_W  Eyebrow_L_H2_W  ...  Lip_h1_L  \\\n",
       "0           0.074501 -1.025311       -0.273121        0.317896  ... -0.485461   \n",
       "1          -0.494539 -0.234723        2.151637        0.741030  ... -1.364071   \n",
       "2          -1.184414  1.019508       -0.621587        0.675260  ... -0.409028   \n",
       "3          -2.224317  3.069776        1.711365        3.198713  ... -0.943542   \n",
       "4          -0.949778 -3.136693       -1.017479       -2.836990  ...  2.218981   \n",
       "...              ...       ...             ...             ...  ...       ...   \n",
       "67303       2.085433 -0.001246       -0.684678       -1.111386  ... -0.232581   \n",
       "67304      -0.341706 -1.171122       -1.139710       -0.729043  ...  1.031585   \n",
       "67305       0.022684 -0.925395       -1.129517       -0.804039  ... -1.552749   \n",
       "67306       0.999174 -1.858378       -0.301002       -1.718476  ...  0.812409   \n",
       "67307      -0.031247 -1.380678       -1.534513       -1.897627  ...  0.704872   \n",
       "\n",
       "       Lip_h5_L  Lip_dh3_L  Lip_height_L  face_up_L  face_down_L  \\\n",
       "0     -0.638260  -1.168916     -1.429228  -0.399381     0.064321   \n",
       "1     -1.649756  -0.114365     -1.331401   2.163930    -1.252541   \n",
       "2      0.665220   1.289591      0.023857   0.386898     0.157466   \n",
       "3      0.597671   0.288644     -0.299054   0.070247     0.287063   \n",
       "4      2.824092   1.380356      0.103716   1.242597     0.827017   \n",
       "...         ...        ...           ...        ...          ...   \n",
       "67303 -0.455388  -0.592585      0.458105  -3.057781     1.112890   \n",
       "67304  1.013650   0.511776     -0.372693  -1.909245     0.844149   \n",
       "67305 -0.481648  -1.393494     -1.711341  -0.083537     0.629206   \n",
       "67306  0.204526  -0.017447      2.027846  -0.400509     1.419143   \n",
       "67307  0.638523   0.902799     -0.486805  -1.215145     0.187233   \n",
       "\n",
       "       face_L_width_L  Eye_to_eyebrow_L_L  eye_to_eyebrow_R_L  Label  \n",
       "0            0.643328            1.024564            1.276503   boss  \n",
       "1           -2.053611           -0.569419            0.243881   boss  \n",
       "2            0.393616           -1.518321           -1.391570   boss  \n",
       "3           -1.495221           -2.074765           -1.844764   boss  \n",
       "4            1.088651           -0.701203            0.314433   boss  \n",
       "...               ...                 ...                 ...    ...  \n",
       "67303        0.991555            1.693874            2.298094  sport  \n",
       "67304        0.721058           -0.262786           -0.675667  sport  \n",
       "67305        1.788860           -1.349675            1.083243  sport  \n",
       "67306        0.225163           -0.506823           -0.119500  sport  \n",
       "67307        1.548236            1.497667            1.165196  sport  \n",
       "\n",
       "[67308 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"./only_Corr_features.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33995f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1]\n",
    "y=df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "690aa3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.to_list()\n",
    "a=['boss', 'doctor', 'entertainer', 'ordinary_people', 'politician', 'sport']\n",
    "for i in range(len(y)):\n",
    "    if y[i] in a:\n",
    "        b=y[i]\n",
    "        y[i]=a.index(b)\n",
    "y = pd.DataFrame(y)\n",
    "y1=y.to_numpy()\n",
    "y=y1.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b33bc54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'max_leaf_nodes': 57, 'min_samples_leaf': 9}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y)\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier(class_weight=\"balanced\")\n",
    "params = {\"max_leaf_nodes\" : np.arange(30,60),\"min_samples_leaf\" : np.arange(2,10), \"max_depth\" : np.arange(5,15)}\n",
    "\n",
    "model_gs = GridSearchCV(model, params, cv=5,scoring=\"recall_macro\")\n",
    "model_gs.fit(X_train, y_train)\n",
    "\n",
    "#save best model\n",
    "model_best = model_gs.best_estimator_\n",
    "\n",
    "#check best n_neigbors value\n",
    "print(model_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00d5c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=9, max_leaf_nodes=57,min_samples_leaf=9,class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f4bfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62351234 0.66130653 0.68686822 0.73309496 0.71660487]\n",
      "Accuracy: 0.6842773830563714 (+/- 0.0782559104677255)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model, X, y, cv=5, scoring='recall_macro')\n",
    "print(scores)\n",
    "\n",
    "print(\"Accuracy: {} (+/- {})\".format(scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcd8247b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of correct sample: 12166\n",
      "accuracy: 0.9037290150051999\n",
      "con_matrix: [[  497    95    41    88    47    28]\n",
      " [    4   112    15     3    34    12]\n",
      " [   30   103   850     4    64    36]\n",
      " [  292   152    14 10452     8    98]\n",
      " [    0    70    13     0   131    11]\n",
      " [    4    11    11     2     6   124]]\n",
      "recall:0.7240661490822909\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "num_correct_samples = accuracy_score(y_test, y_pred, normalize=False)\n",
    "con_matrix = confusion_matrix(y_test, y_pred)\n",
    "recall_w = recall_score(y_test, y_pred,average=\"macro\")\n",
    "\n",
    "print('number of correct sample: {}'.format(num_correct_samples))\n",
    "print('accuracy: {}'.format(accuracy))\n",
    "print('con_matrix: {}'.format(con_matrix))\n",
    "print(f\"recall:{recall_w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90cb49a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
